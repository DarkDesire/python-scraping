{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "textPage = urlopen('http://www.pythonscraping.com/pages/warandpeace/chapter1.txt')\n",
    "print(textPage.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "textPage = urlopen(\n",
    "             'http://www.pythonscraping.com/pages/warandpeace/chapter1-ru.txt')\n",
    "print(textPage.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "\n",
    "textPage = urlopen(\n",
    "             'http://www.pythonscraping.com/pages/warandpeace/chapter1-ru.txt')\n",
    "print(str(textPage.read(), 'utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = urlopen(\"http://en.wikipedia.org/wiki/Python_(programming_language)\")\n",
    "bs = BeautifulSoup(html, \"html.parser\")\n",
    "content = bs.find(\"div\", {\"id\":\"mw-content-text\"}).get_text()\n",
    "content = bytes(content, \"UTF-8\")\n",
    "content = content.decode(\"UTF-8\")\n",
    "print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from io import StringIO\n",
    "import csv\n",
    "\n",
    "data = urlopen('http://pythonscraping.com/files/MontyPythonAlbums.csv').read().decode('ascii', 'ignore')\n",
    "dataFile = StringIO(data)\n",
    "csvReader = csv.reader(dataFile)\n",
    "\n",
    "for row in csvReader:\n",
    "    print(row)\n",
    "    print(\"The album \\\"\"+row[0]+\"\\\" was released in \"+str(row[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from io import StringIO\n",
    "import csv\n",
    "\n",
    "data = urlopen(\"http://pythonscraping.com/files/MontyPythonAlbums.csv\").read().decode('ascii', 'ignore')\n",
    "dataFile = StringIO(data)\n",
    "dictReader = csv.DictReader(dataFile)\n",
    "\n",
    "print(dictReader.fieldnames)\n",
    "\n",
    "for row in dictReader:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'process_pdf' from 'pdfminer.pdfinterp' (c:\\users\\oheld\\pythonprojects\\web-scrapping\\env\\lib\\site-packages\\pdfminer\\pdfinterp.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01murllib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrequest\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m urlopen\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpdfminer\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpdfinterp\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PDFResourceManager, process_pdf\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpdfminer\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconverter\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TextConverter\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpdfminer\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayout\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LAParams\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'process_pdf' from 'pdfminer.pdfinterp' (c:\\users\\oheld\\pythonprojects\\web-scrapping\\env\\lib\\site-packages\\pdfminer\\pdfinterp.py)"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from pdfminer.pdfinterp import PDFResourceManager, process_pdf\n",
    "from pdfminer.converter import TextConverter\n",
    "from pdfminer.layout import LAParams\n",
    "from io import StringIO\n",
    "from io import open\n",
    "\n",
    "def readPDF(pdfFile):\n",
    "    rsrcmgr = PDFResourceManager()\n",
    "    retstr = StringIO()\n",
    "    laparams = LAParams()\n",
    "    device = TextConverter(rsrcmgr, retstr, laparams=laparams)\n",
    "\n",
    "    process_pdf(rsrcmgr, device, pdfFile)\n",
    "    device.close()\n",
    "\n",
    "    content = retstr.getvalue()\n",
    "    retstr.close()\n",
    "    return content\n",
    "\n",
    "pdfFile = urlopen(\"http://pythonscraping.com/pages/warandpeace/chapter1.pdf\")\n",
    "outputString = readPDF(pdfFile)\n",
    "print(outputString)\n",
    "pdfFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "from urllib.request import urlopen\n",
    "from io import BytesIO\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "wordFile = urlopen('http://pythonscraping.com/pages/AWordDocument.docx').read()\n",
    "wordFile = BytesIO(wordFile)\n",
    "document = ZipFile(wordFile)\n",
    "xml_content = document.read('word/document.xml')\n",
    "\n",
    "wordObj = BeautifulSoup(xml_content.decode('utf-8'), 'xml')\n",
    "textStrings = wordObj.find_all('w:t')\n",
    "\n",
    "for textElem in textStrings:\n",
    "    print(textElem.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "textStrings = wordObj.find_all('w:t')\n",
    "\n",
    "for textElem in textStrings:\n",
    "    style = textElem.parent.parent.find('w:pStyle')\n",
    "    if style is not None and style['w:val'] == 'Title':\n",
    "        print('Title is: {}'.format(textElem.text))\n",
    "    else:\n",
    "        print(textElem.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
